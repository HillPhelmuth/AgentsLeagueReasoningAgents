{"stateBag":{"InMemoryChatHistoryProvider":{"messages":[{"role":"user","contents":[{"$type":"text","text":"\r\nStudent topics: Create output for AI-102 learner (intermediate) with 6 hours/week over 8 weeks.\r\nWeekly study hours: 6\r\nDuration in weeks: 8\r\n\r\nCurated resources:\r\n{\u0022rationale\u0022:\u0022For an intermediate AI-102 learner studying 6 hours/week for 8 weeks (~48 hours), the highest ROI is to focus on Microsoft Learn paths that map directly to AI-102 skill domains: (1) implement generative AI solutions (Foundry, prompt flow, RAG, evaluation, responsible AI), and (2) implement knowledge mining \u0026 information extraction (Azure AI Search \u002B Document Intelligence/Content Understanding). These two paths collectively cover major AI-102 weighted areas (generative AI \u002B knowledge mining/information extraction) while also reinforcing planning/responsible AI concepts that appear across the exam.\u0022,\u0022learningPaths\u0022:[{\u0022title\u0022:\u0022Develop generative AI apps in Azure\u0022,\u0022url\u0022:\u0022https://learn.microsoft.com/training/paths/get-started-azure-ai/\u0022,\u0022estimatedHours\u0022:12,\u0022relevance\u0022:\u0022Directly aligns to AI-102 \u2018Implement generative AI solutions\u2019 objectives: Foundry project setup, model selection/deployment, prompt flow, RAG, fine-tuning, evaluation, and responsible generative AI practices.\u0022},{\u0022title\u0022:\u0022Develop AI information extraction solutions in Azure\u0022,\u0022url\u0022:\u0022https://learn.microsoft.com/training/paths/ai-extract-information/\u0022,\u0022estimatedHours\u0022:5,\u0022relevance\u0022:\u0022Directly aligns to AI-102 \u2018Implement knowledge mining and information extraction solutions\u2019 objectives, including Azure AI Search, Document Intelligence (prebuilt \u002B extraction), and Content Understanding for multimodal extraction.\u0022}],\u0022modules\u0022:[{\u0022title\u0022:\u0022Plan and prepare to develop AI solutions on Azure\u0022,\u0022url\u0022:\u0022https://learn.microsoft.com/training/modules/prepare-azure-ai-development/\u0022,\u0022skillFocus\u0022:\u0022AI-102 planning fundamentals: choosing Azure AI services/Foundry components, developer setup, and responsible AI considerations.\u0022},{\u0022title\u0022:\u0022Use AI responsibly with Azure AI Foundry Content Safety\u0022,\u0022url\u0022:\u0022https://learn.microsoft.com/training/modules/responsible-content-safety/\u0022,\u0022skillFocus\u0022:\u0022AI-102 responsible AI: content safety, moderation, and reducing harmful outputs (cross-cutting exam objective).\u0022},{\u0022title\u0022:\u0022Create a knowledge mining solution with Azure AI Search\u0022,\u0022url\u0022:\u0022https://learn.microsoft.com/training/modules/ai-knowldge-mining/\u0022,\u0022skillFocus\u0022:\u0022AI-102 knowledge mining: provisioning search, indexing, enrichment, and querying patterns (including modern semantic/vector concepts).\u0022}],\u0022targets\u0022:[{\u0022title\u0022:\u0022Microsoft Certified: Azure AI Engineer Associate\u0022,\u0022type\u0022:\u0022Certification\u0022,\u0022url\u0022:\u0022https://learn.microsoft.com/credentials/certifications/azure-ai-engineer/\u0022},{\u0022title\u0022:\u0022Exam AI-102: Designing and Implementing a Microsoft Azure AI Solution\u0022,\u0022type\u0022:\u0022Exam\u0022,\u0022url\u0022:\u0022https://learn.microsoft.com/credentials/certifications/exams/ai-102/\u0022}]}\r\n\r\nProduce JSON only matching the provided schema"}]},{"authorName":"study-plan-generator","createdAt":"2026-02-21T06:33:19\u002B00:00","role":"assistant","contents":[{"$type":"text","text":"{\u0022rationale\u0022:\u0022I grouped the resources into two dependency-driven tracks that map to AI-102: (1) generative AI app implementation in Azure AI Foundry (largest scope and most hands-on, so it spans most weeks), and (2) knowledge mining/information extraction (Azure AI Search \u002B Document Intelligence/Content Understanding). I sequenced the plan so you first establish AI-102-ready setup and decision-making (planning module), then build core GenAI skills (Foundry, prompt engineering, prompt flow, RAG, evaluation), then add Responsible AI/Content Safety as a cross-cutting layer before consolidating with knowledge mining and exam-style review. Pacing is ~6 hours/week as six ~60-minute sessions (one rest/catch-up day), with a weekly checkpoint deliverable (small working artifact, notes, or quiz-style self-check) and deliberate review days before moving to more complex topics like RAG, evaluation, and search enrichment.\u0022,\u0022planTitle\u0022:\u0022AI-102 (Intermediate) \u2014 8-Week / 6-Hours-Per-Week Study Plan (GenAI \u002B Knowledge Mining)\u0022,\u0022durationWeeks\u0022:8,\u0022weeklyHours\u0022:6,\u0022weeklyMilestones\u0022:[{\u0022weekNumber\u0022:1,\u0022objective\u0022:\u0022Establish AI-102 foundation: planning, Azure AI service selection, environment readiness, and baseline responsible AI considerations.\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Read/complete: Plan and prepare to develop AI solutions on Azure (module) \u2014 focus on service selection, architecture considerations, and prerequisites.\u0022,\u0022Create a 1-page notes doc: key Azure AI services (Foundry, Azure OpenAI/models in Foundry, AI Search, Document Intelligence) and when to use each.\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Continue/finish: Plan and prepare to develop AI solutions on Azure (module).\u0022,\u0022Set up/verify: Azure subscription access, resource group naming convention, and a simple cost-control plan (budgets/limits you will follow).\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Start Learning Path: Develop generative AI apps in Azure \u2014 complete the first section/module(s) on getting started with Azure AI Foundry (project/workspace concepts).\u0022,\u0022Write down: your target \u201Ccapstone\u201D app idea (simple RAG chatbot over a small document set).\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Continue Learning Path: Develop generative AI apps in Azure \u2014 focus on model choices, deployments/endpoints, and basic prompt usage.\u0022,\u0022Hands-on: run at least a few prompts and capture what changes output quality (system message, constraints, examples).\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Review session: re-skim your notes from Days 1\u20134.\u0022,\u0022Create a quick self-quiz (10 questions) covering: service selection, Foundry concepts, deployment vs model, and basic prompt components.\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Light practice: refine your capstone requirements (data source, expected answers, safety requirements).\u0022,\u0022Checkpoint prep: list the Azure resources you expect to need for the capstone (Foundry project \u002B model endpoint, AI Search, storage if needed).\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: (1) 1-page service selection cheat sheet, (2) capstone app definition \u002B required Azure resources list, (3) 10-question self-quiz answered at \u226580%.\u0022},{\u0022weekNumber\u0022:2,\u0022objective\u0022:\u0022Build core GenAI app skills in Azure AI Foundry: prompts, configuration, and basic app patterns.\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path: Develop generative AI apps in Azure \u2014 complete next module(s) on prompt engineering fundamentals and best practices.\u0022,\u0022Create 5 prompt templates for your capstone (Q\u0026A, summarization, citation request, refusal, follow-up question).\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on structuring prompts (system/developer/user), grounding instructions, and output formatting.\u0022,\u0022Practice: iterate one template through 3 revisions; record what improved and why.\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on building a basic GenAI app workflow in Foundry (where applicable).\u0022,\u0022Draft: an evaluation rubric for your capstone answers (correctness, completeness, safety, citation quality).\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Hands-on consolidation: implement a minimal \u2018chat\u2019 experience (even if just in a playground) using your best prompt template.\u0022,\u0022Document: the final system prompt \u002B rationale.\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Review session: revisit weak spots from Week 2 (prompt structure, formatting constraints).\u0022,\u0022Make a \u2018prompt patterns\u2019 page: few-shot, chain-of-thought avoidance guidance, tool/function calling concept (high level).\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Mini-mock: answer 10 exam-style prompts you write yourself (e.g., \u201CWhen to use RAG vs fine-tuning?\u201D).\u0022,\u0022Refine capstone plan: decide whether RAG is required (yes) and what documents you\u2019ll use (3\u201310 small docs).\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: a versioned set of 5 prompt templates \u002B one finalized system prompt, and a simple evaluation rubric for responses.\u0022},{\u0022weekNumber\u0022:3,\u0022objective\u0022:\u0022Implement RAG fundamentals: retrieval concept, indexing plan, and how it integrates with GenAI answers.\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path: Develop generative AI apps in Azure \u2014 start/complete the RAG-focused content (concepts: grounding, retrieval, embeddings/vector search at a high level).\u0022,\u0022Write: a RAG architecture diagram (boxes/arrows) for your capstone.\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on data preparation concepts (chunking, metadata, citations).\u0022,\u0022Prepare capstone data: collect documents and define chunking/metadata fields you\u2019ll want (title, source, section).\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on retrieval settings and prompt composition for grounded answers.\u0022,\u0022Create: a \u2018grounded answer\u2019 prompt that forces citations and quotes/snippets.\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Hands-on (design-level if tooling differs): simulate retrieval by manually selecting relevant chunks and feeding them to your model prompt to see impact.\u0022,\u0022Record: 3 examples where grounding prevented hallucinations.\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Review session: summarize RAG tradeoffs (latency, freshness, cost, quality).\u0022,\u0022Create flashcards: RAG vs fine-tuning vs prompt-only (use cases, pros/cons).\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Checkpoint build: outline your indexing pipeline steps (ingest \u2192 chunk \u2192 embed/index \u2192 retrieve \u2192 compose prompt \u2192 generate).\u0022,\u0022Identify risks: missing citations, irrelevant chunks, prompt injection; write mitigations.\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: RAG architecture diagram \u002B indexing pipeline outline \u002B 3 grounded-answer examples with citations behavior documented.\u0022},{\u0022weekNumber\u0022:4,\u0022objective\u0022:\u0022Deepen GenAI solution quality: prompt flow/orchestration concepts and evaluation approach (including iteration).\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path: Develop generative AI apps in Azure \u2014 start/complete prompt flow/orchestration content (building multi-step flows, chaining calls).\u0022,\u0022Convert your capstone into a 2\u20133 step flow on paper (retrieve \u2192 generate \u2192 post-check).\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on tool/step outputs, variables, and managing context windows.\u0022,\u0022Update your prompts to clearly separate: retrieved context vs user question vs instructions.\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on evaluation concepts (quality metrics, test sets, regression).\u0022,\u0022Create a tiny test set: 10 questions \u002B expected key points \u002B expected sources.\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Hands-on evaluation: run your 10-question test set (manual is fine) and score with your rubric.\u0022,\u0022Identify top 3 failure modes and propose changes (retrieval, prompt, formatting, safety).\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Review session: tighten notes on evaluation and iteration loops.\u0022,\u0022Update the test set with 5 adversarial questions (prompt injection attempts, sensitive requests, ambiguous queries).\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Iteration: apply 1\u20132 improvements and re-run a subset of the test set to confirm improvement.\u0022,\u0022Write a short changelog (what changed, why, result).\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: (1) 10-question test set \u002B scoring rubric results, (2) documented iteration with before/after evidence for at least 3 questions.\u0022},{\u0022weekNumber\u0022:5,\u0022objective\u0022:\u0022Responsible AI specialization: apply Azure AI Foundry Content Safety concepts and align safeguards with your GenAI app.\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Complete: Use AI responsibly with Azure AI Foundry Content Safety (module) \u2014 focus on harm categories, moderation workflow, and where to apply safety checks.\u0022,\u0022Write: a safety requirements list for your capstone (what to block, what to warn, what to allow with constraints).\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Continue/finish Content Safety module content and knowledge checks.\u0022,\u0022Design: input and output filtering points in your flow (pre-check user input; post-check model output).\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Create a \u2018refusal and redirection\u2019 response template aligned to policy (safe alternative suggestions).\u0022,\u0022Add policy wording to your system prompt (brief, non-verbose, enforceable).\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Red-team practice: test 10 unsafe/edge prompts and verify your desired behavior using your templates and flow design.\u0022,\u0022Document outcomes and adjust refusal thresholds/wording conceptually.\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Review session: summarize responsible AI themes likely to show up on AI-102 (privacy, safety, transparency, human oversight).\u0022,\u0022Update your capstone evaluation rubric with a \u2018safety compliance\u2019 dimension.\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Consolidation: run a mini end-to-end dry run of your capstone flow: retrieve \u2192 generate \u2192 post-check \u2192 final answer.\u0022,\u0022Prepare a 1-page \u2018Responsible AI \u002B Safety\u2019 cheat sheet.\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: a documented safety design (where checks occur) \u002B 10 red-team prompts with expected/observed safe behaviors \u002B updated system prompt and rubric.\u0022},{\u0022weekNumber\u0022:6,\u0022objective\u0022:\u0022Knowledge mining foundations: Azure AI Search concepts\u2014indexing, enrichment, querying patterns\u2014and how it supports RAG.\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Complete: Create a knowledge mining solution with Azure AI Search (module) \u2014 focus on core components (data source, index, indexer, skillsets/enrichment where applicable).\u0022,\u0022Create: an AI Search terminology sheet (index vs indexer vs datasource vs skillset).\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Continue AI Search module \u2014 focus on querying approaches and relevance concepts (semantic vs keyword; vector concepts if covered).\u0022,\u0022Write: 5 example search queries you\u2019d run for your capstone topics (include filters and desired fields).\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Start Learning Path: Develop AI information extraction solutions in Azure \u2014 overview of information extraction and where Search fits.\u0022,\u0022Decide: what fields you will extract/store for retrieval (content, title, url/source, timestamps, tags).\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on Document Intelligence basics (prebuilt vs custom extraction) and integration patterns.\u0022,\u0022Design: how extracted fields would become searchable/indexable.\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Review session: connect RAG \u2194 AI Search (retrieval layer) clearly in your notes.\u0022,\u0022Update your RAG diagram to explicitly include AI Search indexing/query step and returned fields for citations.\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Mini-case study: draft an end-to-end \u2018ingest \u2192 extract \u2192 index \u2192 retrieve \u2192 generate\u2019 pipeline for one document type (PDF, form, web page).\u0022,\u0022List 5 common failure points (OCR errors, missing fields, bad chunking, irrelevant results, stale index) \u002B mitigations.\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: updated end-to-end architecture diagram including AI Search \u002B extraction, plus 5 concrete sample queries and a failure-modes/mitigations list.\u0022},{\u0022weekNumber\u0022:7,\u0022objective\u0022:\u0022Information extraction deepening: Document Intelligence/Content Understanding scenarios and mapping outputs into search \u002B GenAI.\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path: Develop AI information extraction solutions in Azure \u2014 complete remaining modules on extraction scenarios (documents/forms, structured outputs).\u0022,\u0022Create: a sample JSON schema you\u2019d want from extraction (key fields \u002B confidence).\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on applying extraction to build downstream solutions (searchable knowledge base, analytics, workflows).\u0022,\u0022Map: extraction fields \u2192 search index fields \u2192 what the LLM should cite.\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Integrate conceptually: define how RAG prompt should incorporate extracted structured fields (tables, key-value pairs) vs raw text chunks.\u0022,\u0022Write two prompt variants: (A) unstructured context, (B) structured context with JSON \u002B rules.\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Evaluation: add 5 extraction-driven questions to your test set (questions that require specific fields).\u0022,\u0022Define expected citations/fields for each question.\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Review session: quick recap of all AI-102 major areas you covered (planning, GenAI, RAG, evaluation, safety, search, extraction).\u0022,\u0022Create a 2-page final cheat sheet (one page GenAI/RAG, one page Search/Extraction/Responsible AI).\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Mini-mock exam rehearsal: write 25 mixed questions (scenario-based) and answer them using your notes; flag weak areas.\u0022,\u0022Create a final-week fix list (top 5 gaps).\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: expanded test set (at least 15 questions total) including extraction-driven items, plus a 2-page cheat sheet and a prioritized gaps list.\u0022},{\u0022weekNumber\u0022:8,\u0022objective\u0022:\u0022Final consolidation and exam readiness: targeted review, scenario practice, and end-to-end solution articulation for AI-102.\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Targeted review: revisit weakest domain from your gaps list (e.g., AI Search indexing/enrichment or evaluation).\u0022,\u0022Re-answer 10 previously missed/self-made questions without notes first, then correct with notes.\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Targeted review: revisit second-weakest domain.\u0022,\u0022Refine your capstone architecture narrative: be able to explain design choices (why RAG, why Search, where safety fits).\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Run full test set (15\u002B questions) and score with rubric; ensure safety compliance scoring is included.\u0022,\u0022Create a short \u2018exam-day decision tree\u2019 for common scenarios (RAG vs fine-tune; Search vs Document Intelligence).\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Scenario drills: write 5 end-to-end design prompts and answer them in 5\u20137 bullet steps each (services, data flow, evaluation, monitoring/safety).\u0022,\u0022Review Microsoft Learn exam page objectives and check you can map each to something you studied/built.\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Final review: read both learning paths\u2019 summaries; re-check module knowledge checks if available.\u0022,\u0022Update cheat sheets and remove clutter\u2014keep only high-yield exam cues and patterns.\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Light session (avoid burnout): quick recap flashcards \u002B 10-minute architecture explanation out loud.\u0022,\u0022Plan next step: schedule exam date (or set a target window) and identify any last-minute labs you want to repeat.\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: (1) scored full test set with improvement notes, (2) concise end-to-end architecture explanation (written or recorded), (3) final cheat sheets \u002B exam readiness checklist.\u0022}],\u0022briefMessageToUser\u0022:\u0022This 8-week plan keeps you at ~1 hour/day for 6 days/week, with weekly deliverables that steadily build an AI-102-ready skill stack: Foundry GenAI \u2192 RAG \u002B evaluation \u2192 Content Safety \u2192 AI Search \u002B extraction \u2192 final scenario practice. If you complete each weekly checkpoint artifact (diagrams, prompts, test sets, cheat sheets), you\u2019ll have both exam recall and practical design fluency.\u0022}"}],"messageId":"chatcmpl-DBaqF2faZo5Nz8xYRI4kGufxpOxE5"}]}}}