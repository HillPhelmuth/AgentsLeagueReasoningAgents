{"stateBag":{"InMemoryChatHistoryProvider":{"messages":[{"role":"user","contents":[{"$type":"text","text":"\r\nStudent email: student@example.com\r\nStudy plan:\r\n{\u0022rationale\u0022:\u0022I grouped the resources into two dependency-driven tracks that map to AI-102: (1) generative AI app implementation in Azure AI Foundry (largest scope and most hands-on, so it spans most weeks), and (2) knowledge mining/information extraction (Azure AI Search \u002B Document Intelligence/Content Understanding). I sequenced the plan so you first establish AI-102-ready setup and decision-making (planning module), then build core GenAI skills (Foundry, prompt engineering, prompt flow, RAG, evaluation), then add Responsible AI/Content Safety as a cross-cutting layer before consolidating with knowledge mining and exam-style review. Pacing is ~6 hours/week as six ~60-minute sessions (one rest/catch-up day), with a weekly checkpoint deliverable (small working artifact, notes, or quiz-style self-check) and deliberate review days before moving to more complex topics like RAG, evaluation, and search enrichment.\u0022,\u0022planTitle\u0022:\u0022AI-102 (Intermediate) \u2014 8-Week / 6-Hours-Per-Week Study Plan (GenAI \u002B Knowledge Mining)\u0022,\u0022durationWeeks\u0022:8,\u0022weeklyHours\u0022:6,\u0022weeklyMilestones\u0022:[{\u0022weekNumber\u0022:1,\u0022objective\u0022:\u0022Establish AI-102 foundation: planning, Azure AI service selection, environment readiness, and baseline responsible AI considerations.\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Read/complete: Plan and prepare to develop AI solutions on Azure (module) \u2014 focus on service selection, architecture considerations, and prerequisites.\u0022,\u0022Create a 1-page notes doc: key Azure AI services (Foundry, Azure OpenAI/models in Foundry, AI Search, Document Intelligence) and when to use each.\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Continue/finish: Plan and prepare to develop AI solutions on Azure (module).\u0022,\u0022Set up/verify: Azure subscription access, resource group naming convention, and a simple cost-control plan (budgets/limits you will follow).\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Start Learning Path: Develop generative AI apps in Azure \u2014 complete the first section/module(s) on getting started with Azure AI Foundry (project/workspace concepts).\u0022,\u0022Write down: your target \u201Ccapstone\u201D app idea (simple RAG chatbot over a small document set).\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Continue Learning Path: Develop generative AI apps in Azure \u2014 focus on model choices, deployments/endpoints, and basic prompt usage.\u0022,\u0022Hands-on: run at least a few prompts and capture what changes output quality (system message, constraints, examples).\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Review session: re-skim your notes from Days 1\u20134.\u0022,\u0022Create a quick self-quiz (10 questions) covering: service selection, Foundry concepts, deployment vs model, and basic prompt components.\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Light practice: refine your capstone requirements (data source, expected answers, safety requirements).\u0022,\u0022Checkpoint prep: list the Azure resources you expect to need for the capstone (Foundry project \u002B model endpoint, AI Search, storage if needed).\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: (1) 1-page service selection cheat sheet, (2) capstone app definition \u002B required Azure resources list, (3) 10-question self-quiz answered at \u226580%.\u0022},{\u0022weekNumber\u0022:2,\u0022objective\u0022:\u0022Build core GenAI app skills in Azure AI Foundry: prompts, configuration, and basic app patterns.\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path: Develop generative AI apps in Azure \u2014 complete next module(s) on prompt engineering fundamentals and best practices.\u0022,\u0022Create 5 prompt templates for your capstone (Q\u0026A, summarization, citation request, refusal, follow-up question).\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on structuring prompts (system/developer/user), grounding instructions, and output formatting.\u0022,\u0022Practice: iterate one template through 3 revisions; record what improved and why.\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on building a basic GenAI app workflow in Foundry (where applicable).\u0022,\u0022Draft: an evaluation rubric for your capstone answers (correctness, completeness, safety, citation quality).\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Hands-on consolidation: implement a minimal \u2018chat\u2019 experience (even if just in a playground) using your best prompt template.\u0022,\u0022Document: the final system prompt \u002B rationale.\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Review session: revisit weak spots from Week 2 (prompt structure, formatting constraints).\u0022,\u0022Make a \u2018prompt patterns\u2019 page: few-shot, chain-of-thought avoidance guidance, tool/function calling concept (high level).\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Mini-mock: answer 10 exam-style prompts you write yourself (e.g., \u201CWhen to use RAG vs fine-tuning?\u201D).\u0022,\u0022Refine capstone plan: decide whether RAG is required (yes) and what documents you\u2019ll use (3\u201310 small docs).\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: a versioned set of 5 prompt templates \u002B one finalized system prompt, and a simple evaluation rubric for responses.\u0022},{\u0022weekNumber\u0022:3,\u0022objective\u0022:\u0022Implement RAG fundamentals: retrieval concept, indexing plan, and how it integrates with GenAI answers.\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path: Develop generative AI apps in Azure \u2014 start/complete the RAG-focused content (concepts: grounding, retrieval, embeddings/vector search at a high level).\u0022,\u0022Write: a RAG architecture diagram (boxes/arrows) for your capstone.\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on data preparation concepts (chunking, metadata, citations).\u0022,\u0022Prepare capstone data: collect documents and define chunking/metadata fields you\u2019ll want (title, source, section).\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on retrieval settings and prompt composition for grounded answers.\u0022,\u0022Create: a \u2018grounded answer\u2019 prompt that forces citations and quotes/snippets.\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Hands-on (design-level if tooling differs): simulate retrieval by manually selecting relevant chunks and feeding them to your model prompt to see impact.\u0022,\u0022Record: 3 examples where grounding prevented hallucinations.\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Review session: summarize RAG tradeoffs (latency, freshness, cost, quality).\u0022,\u0022Create flashcards: RAG vs fine-tuning vs prompt-only (use cases, pros/cons).\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Checkpoint build: outline your indexing pipeline steps (ingest \u2192 chunk \u2192 embed/index \u2192 retrieve \u2192 compose prompt \u2192 generate).\u0022,\u0022Identify risks: missing citations, irrelevant chunks, prompt injection; write mitigations.\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: RAG architecture diagram \u002B indexing pipeline outline \u002B 3 grounded-answer examples with citations behavior documented.\u0022},{\u0022weekNumber\u0022:4,\u0022objective\u0022:\u0022Deepen GenAI solution quality: prompt flow/orchestration concepts and evaluation approach (including iteration).\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path: Develop generative AI apps in Azure \u2014 start/complete prompt flow/orchestration content (building multi-step flows, chaining calls).\u0022,\u0022Convert your capstone into a 2\u20133 step flow on paper (retrieve \u2192 generate \u2192 post-check).\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on tool/step outputs, variables, and managing context windows.\u0022,\u0022Update your prompts to clearly separate: retrieved context vs user question vs instructions.\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on evaluation concepts (quality metrics, test sets, regression).\u0022,\u0022Create a tiny test set: 10 questions \u002B expected key points \u002B expected sources.\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Hands-on evaluation: run your 10-question test set (manual is fine) and score with your rubric.\u0022,\u0022Identify top 3 failure modes and propose changes (retrieval, prompt, formatting, safety).\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Review session: tighten notes on evaluation and iteration loops.\u0022,\u0022Update the test set with 5 adversarial questions (prompt injection attempts, sensitive requests, ambiguous queries).\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Iteration: apply 1\u20132 improvements and re-run a subset of the test set to confirm improvement.\u0022,\u0022Write a short changelog (what changed, why, result).\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: (1) 10-question test set \u002B scoring rubric results, (2) documented iteration with before/after evidence for at least 3 questions.\u0022},{\u0022weekNumber\u0022:5,\u0022objective\u0022:\u0022Responsible AI specialization: apply Azure AI Foundry Content Safety concepts and align safeguards with your GenAI app.\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Complete: Use AI responsibly with Azure AI Foundry Content Safety (module) \u2014 focus on harm categories, moderation workflow, and where to apply safety checks.\u0022,\u0022Write: a safety requirements list for your capstone (what to block, what to warn, what to allow with constraints).\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Continue/finish Content Safety module content and knowledge checks.\u0022,\u0022Design: input and output filtering points in your flow (pre-check user input; post-check model output).\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Create a \u2018refusal and redirection\u2019 response template aligned to policy (safe alternative suggestions).\u0022,\u0022Add policy wording to your system prompt (brief, non-verbose, enforceable).\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Red-team practice: test 10 unsafe/edge prompts and verify your desired behavior using your templates and flow design.\u0022,\u0022Document outcomes and adjust refusal thresholds/wording conceptually.\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Review session: summarize responsible AI themes likely to show up on AI-102 (privacy, safety, transparency, human oversight).\u0022,\u0022Update your capstone evaluation rubric with a \u2018safety compliance\u2019 dimension.\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Consolidation: run a mini end-to-end dry run of your capstone flow: retrieve \u2192 generate \u2192 post-check \u2192 final answer.\u0022,\u0022Prepare a 1-page \u2018Responsible AI \u002B Safety\u2019 cheat sheet.\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: a documented safety design (where checks occur) \u002B 10 red-team prompts with expected/observed safe behaviors \u002B updated system prompt and rubric.\u0022},{\u0022weekNumber\u0022:6,\u0022objective\u0022:\u0022Knowledge mining foundations: Azure AI Search concepts\u2014indexing, enrichment, querying patterns\u2014and how it supports RAG.\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Complete: Create a knowledge mining solution with Azure AI Search (module) \u2014 focus on core components (data source, index, indexer, skillsets/enrichment where applicable).\u0022,\u0022Create: an AI Search terminology sheet (index vs indexer vs datasource vs skillset).\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Continue AI Search module \u2014 focus on querying approaches and relevance concepts (semantic vs keyword; vector concepts if covered).\u0022,\u0022Write: 5 example search queries you\u2019d run for your capstone topics (include filters and desired fields).\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Start Learning Path: Develop AI information extraction solutions in Azure \u2014 overview of information extraction and where Search fits.\u0022,\u0022Decide: what fields you will extract/store for retrieval (content, title, url/source, timestamps, tags).\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on Document Intelligence basics (prebuilt vs custom extraction) and integration patterns.\u0022,\u0022Design: how extracted fields would become searchable/indexable.\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Review session: connect RAG \u2194 AI Search (retrieval layer) clearly in your notes.\u0022,\u0022Update your RAG diagram to explicitly include AI Search indexing/query step and returned fields for citations.\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Mini-case study: draft an end-to-end \u2018ingest \u2192 extract \u2192 index \u2192 retrieve \u2192 generate\u2019 pipeline for one document type (PDF, form, web page).\u0022,\u0022List 5 common failure points (OCR errors, missing fields, bad chunking, irrelevant results, stale index) \u002B mitigations.\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: updated end-to-end architecture diagram including AI Search \u002B extraction, plus 5 concrete sample queries and a failure-modes/mitigations list.\u0022},{\u0022weekNumber\u0022:7,\u0022objective\u0022:\u0022Information extraction deepening: Document Intelligence/Content Understanding scenarios and mapping outputs into search \u002B GenAI.\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path: Develop AI information extraction solutions in Azure \u2014 complete remaining modules on extraction scenarios (documents/forms, structured outputs).\u0022,\u0022Create: a sample JSON schema you\u2019d want from extraction (key fields \u002B confidence).\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Learning Path continuation \u2014 focus on applying extraction to build downstream solutions (searchable knowledge base, analytics, workflows).\u0022,\u0022Map: extraction fields \u2192 search index fields \u2192 what the LLM should cite.\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Integrate conceptually: define how RAG prompt should incorporate extracted structured fields (tables, key-value pairs) vs raw text chunks.\u0022,\u0022Write two prompt variants: (A) unstructured context, (B) structured context with JSON \u002B rules.\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Evaluation: add 5 extraction-driven questions to your test set (questions that require specific fields).\u0022,\u0022Define expected citations/fields for each question.\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Review session: quick recap of all AI-102 major areas you covered (planning, GenAI, RAG, evaluation, safety, search, extraction).\u0022,\u0022Create a 2-page final cheat sheet (one page GenAI/RAG, one page Search/Extraction/Responsible AI).\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Mini-mock exam rehearsal: write 25 mixed questions (scenario-based) and answer them using your notes; flag weak areas.\u0022,\u0022Create a final-week fix list (top 5 gaps).\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: expanded test set (at least 15 questions total) including extraction-driven items, plus a 2-page cheat sheet and a prioritized gaps list.\u0022},{\u0022weekNumber\u0022:8,\u0022objective\u0022:\u0022Final consolidation and exam readiness: targeted review, scenario practice, and end-to-end solution articulation for AI-102.\u0022,\u0022sessions\u0022:[{\u0022day\u0022:\u0022Day 1\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Targeted review: revisit weakest domain from your gaps list (e.g., AI Search indexing/enrichment or evaluation).\u0022,\u0022Re-answer 10 previously missed/self-made questions without notes first, then correct with notes.\u0022]},{\u0022day\u0022:\u0022Day 2\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Targeted review: revisit second-weakest domain.\u0022,\u0022Refine your capstone architecture narrative: be able to explain design choices (why RAG, why Search, where safety fits).\u0022]},{\u0022day\u0022:\u0022Day 3\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Run full test set (15\u002B questions) and score with rubric; ensure safety compliance scoring is included.\u0022,\u0022Create a short \u2018exam-day decision tree\u2019 for common scenarios (RAG vs fine-tune; Search vs Document Intelligence).\u0022]},{\u0022day\u0022:\u0022Day 4\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Scenario drills: write 5 end-to-end design prompts and answer them in 5\u20137 bullet steps each (services, data flow, evaluation, monitoring/safety).\u0022,\u0022Review Microsoft Learn exam page objectives and check you can map each to something you studied/built.\u0022]},{\u0022day\u0022:\u0022Day 5\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Final review: read both learning paths\u2019 summaries; re-check module knowledge checks if available.\u0022,\u0022Update cheat sheets and remove clutter\u2014keep only high-yield exam cues and patterns.\u0022]},{\u0022day\u0022:\u0022Day 6\u0022,\u0022durationMinutes\u0022:60,\u0022tasks\u0022:[\u0022Light session (avoid burnout): quick recap flashcards \u002B 10-minute architecture explanation out loud.\u0022,\u0022Plan next step: schedule exam date (or set a target window) and identify any last-minute labs you want to repeat.\u0022]}],\u0022checkpoint\u0022:\u0022Deliverable: (1) scored full test set with improvement notes, (2) concise end-to-end architecture explanation (written or recorded), (3) final cheat sheets \u002B exam readiness checklist.\u0022}],\u0022briefMessageToUser\u0022:\u0022This 8-week plan keeps you at ~1 hour/day for 6 days/week, with weekly deliverables that steadily build an AI-102-ready skill stack: Foundry GenAI \u2192 RAG \u002B evaluation \u2192 Content Safety \u2192 AI Search \u002B extraction \u2192 final scenario practice. If you complete each weekly checkpoint artifact (diagrams, prompts, test sets, cheat sheets), you\u2019ll have both exam recall and practical design fluency.\u0022}\r\n\r\nProduce JSON only matching the provided schema"}]},{"authorName":"engagement-agent","createdAt":"2026-02-21T06:34:26\u002B00:00","role":"assistant","contents":[{"$type":"text","text":"{\u0022rationale\u0022:\u0022This engagement plan mirrors the student\u2019s 8-week, 6-sessions-per-week pacing and reinforces weekly checkpoint deliverables for AI-102 by nudging daily completion of Microsoft Learn modules plus a concrete artifact (notes, prompts, diagrams, test sets) that builds toward an end-to-end GenAI \u002B RAG \u002B Safety \u002B Search/Extraction capstone.\u0022,\u0022recipientEmail\u0022:\u0022student@example.com\u0022,\u0022reminders\u0022:[{\u0022schedule\u0022:\u00222026-02-24T09:00:00\u0022,\u0022subject\u0022:\u0022Week 1 Day 1 \u2014 Plan \u0026 prepare module \u002B service-selection notes\u0022,\u0022body\u0022:\u0022Complete the Microsoft Learn module on planning/prep for Azure AI solutions, then capture a 1-page cheat sheet of when to use Foundry, Azure AI Search, and Document Intelligence so your AI-102 service choices become automatic. https://learn.microsoft.com/en-us/training/modules/plan-prepare-develop-ai-solutions-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/modules/plan-prepare-develop-ai-solutions-azure/\u0022},{\u0022schedule\u0022:\u00222026-02-25T09:00:00\u0022,\u0022subject\u0022:\u0022Week 1 Day 2 \u2014 Finish planning module \u002B environment readiness\u0022,\u0022body\u0022:\u0022Finish the planning/prep module and verify your subscription/resource-group \u002B basic budget limits today\u2014clean setup now prevents friction when you start building in Foundry. https://learn.microsoft.com/en-us/training/modules/plan-prepare-develop-ai-solutions-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/modules/plan-prepare-develop-ai-solutions-azure/\u0022},{\u0022schedule\u0022:\u00222026-02-26T09:00:00\u0022,\u0022subject\u0022:\u0022Week 1 Day 3 \u2014 Start GenAI apps learning path (Foundry basics) \u002B capstone idea\u0022,\u0022body\u0022:\u0022Start the \u201CDevelop generative AI apps in Azure\u201D learning path and focus on Azure AI Foundry project/workspace concepts; finish by writing your simple RAG chatbot capstone idea in 3\u20135 lines. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-02-27T09:00:00\u0022,\u0022subject\u0022:\u0022Week 1 Day 4 \u2014 Foundry model choices/deployments \u002B prompt practice\u0022,\u0022body\u0022:\u0022Continue the GenAI apps learning path and practice basic prompting\u2014run a few variations (system message, constraints, examples) and note what improves output quality. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-02-28T09:00:00\u0022,\u0022subject\u0022:\u0022Week 1 Day 5 \u2014 Review \u002B 10-question self-quiz\u0022,\u0022body\u0022:\u0022Do a fast re-skim of your Week 1 notes, then write and answer a 10-question self-quiz (service selection, Foundry concepts, deployment vs model, prompt components) to lock in recall. https://learn.microsoft.com/en-us/training/modules/plan-prepare-develop-ai-solutions-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/modules/plan-prepare-develop-ai-solutions-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-01T09:00:00\u0022,\u0022subject\u0022:\u0022Week 1 Day 6 \u2014 Capstone requirements \u002B resources list (checkpoint prep)\u0022,\u0022body\u0022:\u0022Refine your capstone requirements (docs, expected answers, safety needs) and list the Azure resources you\u2019ll need so Week 2 execution stays focused. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-03T09:00:00\u0022,\u0022subject\u0022:\u0022Week 2 Day 1 \u2014 Prompt engineering fundamentals \u002B 5 templates\u0022,\u0022body\u0022:\u0022Complete the prompt-engineering sections in the GenAI apps learning path, then draft 5 prompt templates for your capstone (Q\u0026A, summary, citations, refusal, follow-up). https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-04T09:00:00\u0022,\u0022subject\u0022:\u0022Week 2 Day 2 \u2014 Prompt structure \u002B iterate 1 template 3 times\u0022,\u0022body\u0022:\u0022Focus today on system/developer/user structure and output formatting; run 3 revisions of one template and record what improved and why. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-05T09:00:00\u0022,\u0022subject\u0022:\u0022Week 2 Day 3 \u2014 Basic app workflow concepts \u002B evaluation rubric draft\u0022,\u0022body\u0022:\u0022Continue the learning path and connect prompts to a basic app/workflow mindset; end by drafting your scoring rubric (correctness, completeness, safety, citation quality). https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-06T09:00:00\u0022,\u0022subject\u0022:\u0022Week 2 Day 4 \u2014 Minimal chat experience \u002B finalize system prompt\u0022,\u0022body\u0022:\u0022Implement a minimal chat experience (playground is fine) using your best template, then write the final system prompt plus a short rationale so you can defend choices on AI-102 scenarios. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-07T09:00:00\u0022,\u0022subject\u0022:\u0022Week 2 Day 5 \u2014 Review weak spots \u002B prompt patterns page\u0022,\u0022body\u0022:\u0022Revisit any weak areas (structure/formatting constraints) and create a one-page \u201Cprompt patterns\u201D reference you can reuse during RAG and evaluation weeks. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-08T09:00:00\u0022,\u0022subject\u0022:\u0022Week 2 Day 6 \u2014 Mini-mock \u002B confirm capstone docs for RAG\u0022,\u0022body\u0022:\u0022Write and answer 10 exam-style questions (e.g., RAG vs fine-tuning) and lock in your 3\u201310 capstone documents so Week 3 RAG work is concrete. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-10T09:00:00\u0022,\u0022subject\u0022:\u0022Week 3 Day 1 \u2014 RAG concepts \u002B architecture diagram\u0022,\u0022body\u0022:\u0022Go through the RAG-focused content (grounding, retrieval, embeddings/vector search at high level) and draw your capstone RAG architecture diagram (boxes/arrows). https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-11T09:00:00\u0022,\u0022subject\u0022:\u0022Week 3 Day 2 \u2014 Data prep (chunking/metadata) \u002B collect docs\u0022,\u0022body\u0022:\u0022Study chunking/metadata/citations concepts, then collect your docs and define your fields (title, source, section) so retrieval can produce reliable citations. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-12T09:00:00\u0022,\u0022subject\u0022:\u0022Week 3 Day 3 \u2014 Retrieval settings \u002B grounded-answer prompt with citations\u0022,\u0022body\u0022:\u0022Focus on retrieval \u002B prompt composition for grounded answers, then write a prompt that forces citations/quotes so you can measure hallucination reduction later. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-13T09:00:00\u0022,\u0022subject\u0022:\u0022Week 3 Day 4 \u2014 Manual retrieval simulation \u002B 3 grounding wins\u0022,\u0022body\u0022:\u0022Simulate retrieval by manually selecting relevant chunks and feeding them into your prompt; capture 3 examples where grounding clearly prevented hallucinations. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-14T09:00:00\u0022,\u0022subject\u0022:\u0022Week 3 Day 5 \u2014 RAG tradeoffs \u002B flashcards (RAG vs fine-tune vs prompt-only)\u0022,\u0022body\u0022:\u0022Summarize RAG tradeoffs (latency, freshness, cost, quality) and make quick flashcards comparing RAG vs fine-tuning vs prompt-only\u2014this shows up constantly in AI-102 scenarios. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-15T09:00:00\u0022,\u0022subject\u0022:\u0022Week 3 Day 6 \u2014 Indexing pipeline outline \u002B risks/mitigations\u0022,\u0022body\u0022:\u0022Outline your end-to-end indexing pipeline (ingest\u2192chunk\u2192embed/index\u2192retrieve\u2192compose\u2192generate) and write mitigations for citations gaps, irrelevant chunks, and prompt injection. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-17T09:00:00\u0022,\u0022subject\u0022:\u0022Week 4 Day 1 \u2014 Prompt flow/orchestration \u002B 2\u20133 step flow on paper\u0022,\u0022body\u0022:\u0022Complete the prompt flow/orchestration content and convert your capstone into a simple 2\u20133 step flow (retrieve\u2192generate\u2192post-check) to prepare for evaluation and safety. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-18T09:00:00\u0022,\u0022subject\u0022:\u0022Week 4 Day 2 \u2014 Context management \u002B separate context/question/instructions\u0022,\u0022body\u0022:\u0022Study variables/context-window management, then update your prompts to clearly separate retrieved context vs the user question vs the instructions\u2014this is an easy quality win. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-19T09:00:00\u0022,\u0022subject\u0022:\u0022Week 4 Day 3 \u2014 Evaluation concepts \u002B build 10-question test set\u0022,\u0022body\u0022:\u0022Focus on evaluation/test sets/regression ideas and create a tiny 10-question test set with expected key points \u002B expected sources so iteration is measurable. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-20T09:00:00\u0022,\u0022subject\u0022:\u0022Week 4 Day 4 \u2014 Run evaluation \u002B identify top 3 failure modes\u0022,\u0022body\u0022:\u0022Run your 10-question test set and score it with your rubric; pick the top 3 failure modes and propose changes (retrieval/prompt/formatting/safety). https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-21T09:00:00\u0022,\u0022subject\u0022:\u0022Week 4 Day 5 \u2014 Review iteration loop \u002B add 5 adversarial questions\u0022,\u0022body\u0022:\u0022Tighten your evaluation notes, then add 5 adversarial questions (injection, sensitive requests, ambiguity) to harden your solution before Content Safety week. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-22T09:00:00\u0022,\u0022subject\u0022:\u0022Week 4 Day 6 \u2014 Apply improvements \u002B re-test \u002B changelog\u0022,\u0022body\u0022:\u0022Apply 1\u20132 improvements and re-run a subset of the test set; write a short changelog (what changed, why, result) to build exam-ready justification skills. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-03-24T09:00:00\u0022,\u0022subject\u0022:\u0022Week 5 Day 1 \u2014 Content Safety module \u002B safety requirements list\u0022,\u0022body\u0022:\u0022Complete the Content Safety module section on harm categories/moderation workflow, then write your capstone safety requirements (block/warn/allow-with-constraints). https://learn.microsoft.com/en-us/training/modules/use-ai-responsibly-with-azure-ai-foundry-content-safety/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/modules/use-ai-responsibly-with-azure-ai-foundry-content-safety/\u0022},{\u0022schedule\u0022:\u00222026-03-25T09:00:00\u0022,\u0022subject\u0022:\u0022Week 5 Day 2 \u2014 Finish Content Safety \u002B design pre/post filtering points\u0022,\u0022body\u0022:\u0022Finish the module and design exactly where you\u2019ll filter (pre-check user input, post-check model output) so safety is part of the architecture\u2014not an afterthought. https://learn.microsoft.com/en-us/training/modules/use-ai-responsibly-with-azure-ai-foundry-content-safety/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/modules/use-ai-responsibly-with-azure-ai-foundry-content-safety/\u0022},{\u0022schedule\u0022:\u00222026-03-26T09:00:00\u0022,\u0022subject\u0022:\u0022Week 5 Day 3 \u2014 Refusal/redirection template \u002B policy wording in system prompt\u0022,\u0022body\u0022:\u0022Write a refusal-and-redirection template aligned to policy and add brief enforceable policy wording to your system prompt so the model behavior is consistent under pressure. https://learn.microsoft.com/en-us/training/modules/use-ai-responsibly-with-azure-ai-foundry-content-safety/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/modules/use-ai-responsibly-with-azure-ai-foundry-content-safety/\u0022},{\u0022schedule\u0022:\u00222026-03-27T09:00:00\u0022,\u0022subject\u0022:\u0022Week 5 Day 4 \u2014 Red-team 10 prompts \u002B adjust thresholds/wording\u0022,\u0022body\u0022:\u0022Red-team your app with 10 unsafe/edge prompts and document observed vs expected behavior; tune wording/threshold assumptions until responses are predictably safe. https://learn.microsoft.com/en-us/training/modules/use-ai-responsibly-with-azure-ai-foundry-content-safety/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/modules/use-ai-responsibly-with-azure-ai-foundry-content-safety/\u0022},{\u0022schedule\u0022:\u00222026-03-28T09:00:00\u0022,\u0022subject\u0022:\u0022Week 5 Day 5 \u2014 Responsible AI recap \u002B add safety compliance to rubric\u0022,\u0022body\u0022:\u0022Summarize Responsible AI themes (privacy, safety, transparency, human oversight) and add \u201Csafety compliance\u201D to your evaluation rubric so quality and safety are scored together. https://learn.microsoft.com/en-us/training/modules/use-ai-responsibly-with-azure-ai-foundry-content-safety/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/modules/use-ai-responsibly-with-azure-ai-foundry-content-safety/\u0022},{\u0022schedule\u0022:\u00222026-03-29T09:00:00\u0022,\u0022subject\u0022:\u0022Week 5 Day 6 \u2014 End-to-end dry run \u002B 1-page Safety cheat sheet\u0022,\u0022body\u0022:\u0022Run an end-to-end dry run (retrieve\u2192generate\u2192post-check\u2192final) and produce a 1-page Responsible AI \u002B Safety cheat sheet you can reuse during final-week scenario drills. https://learn.microsoft.com/en-us/training/modules/use-ai-responsibly-with-azure-ai-foundry-content-safety/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/modules/use-ai-responsibly-with-azure-ai-foundry-content-safety/\u0022},{\u0022schedule\u0022:\u00222026-03-31T09:00:00\u0022,\u0022subject\u0022:\u0022Week 6 Day 1 \u2014 AI Search module \u002B terminology sheet\u0022,\u0022body\u0022:\u0022Complete the AI Search knowledge-mining module and make a terminology sheet (index vs indexer vs data source vs skillset) to keep the pipeline clear in exam scenarios. https://learn.microsoft.com/en-us/training/modules/create-knowledge-mining-solution-azure-ai-search/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/modules/create-knowledge-mining-solution-azure-ai-search/\u0022},{\u0022schedule\u0022:\u00222026-04-01T09:00:00\u0022,\u0022subject\u0022:\u0022Week 6 Day 2 \u2014 AI Search querying/relevance \u002B 5 sample queries\u0022,\u0022body\u0022:\u0022Continue the AI Search module on querying and relevance, then write 5 realistic queries (with filters/fields) you\u2019d run for your capstone retrieval. https://learn.microsoft.com/en-us/training/modules/create-knowledge-mining-solution-azure-ai-search/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/modules/create-knowledge-mining-solution-azure-ai-search/\u0022},{\u0022schedule\u0022:\u00222026-04-02T09:00:00\u0022,\u0022subject\u0022:\u0022Week 6 Day 3 \u2014 Start info extraction learning path \u002B decide fields to extract/store\u0022,\u0022body\u0022:\u0022Start the information extraction learning path and decide which fields you\u2019ll extract/store (content, title, source URL, timestamps, tags) to make retrieval and citations reliable. https://learn.microsoft.com/en-us/training/paths/develop-ai-information-extraction-solutions-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-ai-information-extraction-solutions-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-04-03T09:00:00\u0022,\u0022subject\u0022:\u0022Week 6 Day 4 \u2014 Document Intelligence basics \u002B design searchable extracted fields\u0022,\u0022body\u0022:\u0022Focus on Document Intelligence basics (prebuilt vs custom) and sketch how extracted fields map into a search index so your RAG layer can cite structured outputs. https://learn.microsoft.com/en-us/training/paths/develop-ai-information-extraction-solutions-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-ai-information-extraction-solutions-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-04-04T09:00:00\u0022,\u0022subject\u0022:\u0022Week 6 Day 5 \u2014 Connect RAG \u2194 AI Search \u002B update RAG diagram\u0022,\u0022body\u0022:\u0022Update your notes to clearly position AI Search as the retrieval layer for RAG, then revise your RAG diagram to show indexing/query \u002B returned citation fields. https://learn.microsoft.com/en-us/training/modules/create-knowledge-mining-solution-azure-ai-search/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/modules/create-knowledge-mining-solution-azure-ai-search/\u0022},{\u0022schedule\u0022:\u00222026-04-05T09:00:00\u0022,\u0022subject\u0022:\u0022Week 6 Day 6 \u2014 Draft ingest\u2192extract\u2192index\u2192retrieve\u2192generate \u002B failure modes\u0022,\u0022body\u0022:\u0022Draft an end-to-end pipeline for one doc type (PDF/form/web) and list 5 likely failure points with mitigations so you can answer troubleshooting/design questions on AI-102. https://learn.microsoft.com/en-us/training/paths/develop-ai-information-extraction-solutions-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-ai-information-extraction-solutions-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-04-07T09:00:00\u0022,\u0022subject\u0022:\u0022Week 7 Day 1 \u2014 Extraction scenarios \u002B sample JSON schema\u0022,\u0022body\u0022:\u0022Complete the remaining extraction-scenario modules, then define a sample JSON schema (fields \u002B confidence) you\u2019d want from extraction to power search and RAG. https://learn.microsoft.com/en-us/training/paths/develop-ai-information-extraction-solutions-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-ai-information-extraction-solutions-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-04-08T09:00:00\u0022,\u0022subject\u0022:\u0022Week 7 Day 2 \u2014 Map extraction\u2192search index\u2192LLM citations\u0022,\u0022body\u0022:\u0022Continue the learning path and explicitly map extraction fields \u2192 search index fields \u2192 what the LLM must cite, so your design remains traceable end-to-end. https://learn.microsoft.com/en-us/training/paths/develop-ai-information-extraction-solutions-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-ai-information-extraction-solutions-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-04-09T09:00:00\u0022,\u0022subject\u0022:\u0022Week 7 Day 3 \u2014 Structured vs unstructured context \u002B write 2 prompt variants\u0022,\u0022body\u0022:\u0022Define how your RAG prompt should use structured fields (JSON/tables/KVP) vs raw chunks, then write two prompt variants (unstructured vs structured) for comparison. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-04-10T09:00:00\u0022,\u0022subject\u0022:\u0022Week 7 Day 4 \u2014 Add 5 extraction-driven questions \u002B expected citations\u0022,\u0022body\u0022:\u0022Add 5 extraction-driven questions to your test set and define expected fields/citations for each\u2014this forces you to validate the extraction\u2192retrieval\u2192answer loop. https://learn.microsoft.com/en-us/training/paths/develop-ai-information-extraction-solutions-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-ai-information-extraction-solutions-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-04-11T09:00:00\u0022,\u0022subject\u0022:\u0022Week 7 Day 5 \u2014 Full recap \u002B build 2-page final cheat sheet\u0022,\u0022body\u0022:\u0022Do a quick recap of planning, GenAI, RAG, evaluation, safety, search, and extraction; then create a clean 2-page cheat sheet (GenAI/RAG \u002B Search/Extraction/RAI). https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-102/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-102/\u0022},{\u0022schedule\u0022:\u00222026-04-12T09:00:00\u0022,\u0022subject\u0022:\u0022Week 7 Day 6 \u2014 Mini-mock (25 questions) \u002B finalize top-5 gaps list\u0022,\u0022body\u0022:\u0022Write and answer 25 mixed scenario questions using your notes, then produce a prioritized top-5 gaps list so Week 8 review is targeted and efficient. https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-102/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-102/\u0022},{\u0022schedule\u0022:\u00222026-04-14T09:00:00\u0022,\u0022subject\u0022:\u0022Week 8 Day 1 \u2014 Review weakest domain \u002B re-answer 10 missed questions\u0022,\u0022body\u0022:\u0022Hit your #1 weak domain from the gaps list, then re-answer 10 previously missed questions without notes first to simulate exam pressure and confirm improvement. https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-102/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-102/\u0022},{\u0022schedule\u0022:\u00222026-04-15T09:00:00\u0022,\u0022subject\u0022:\u0022Week 8 Day 2 \u2014 Review 2nd weak domain \u002B capstone architecture narrative\u0022,\u0022body\u0022:\u0022Review your second-weakest area and refine your capstone architecture narrative (why RAG, why Search, where safety fits) so you can explain decisions clearly. https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-102/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-102/\u0022},{\u0022schedule\u0022:\u00222026-04-16T09:00:00\u0022,\u0022subject\u0022:\u0022Week 8 Day 3 \u2014 Run full test set \u002B build exam-day decision tree\u0022,\u0022body\u0022:\u0022Run your full 15\u002B question test set with rubric scoring (include safety compliance), then write a quick decision tree (RAG vs fine-tune; Search vs Doc Intelligence) for exam speed. https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-102/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-102/\u0022},{\u0022schedule\u0022:\u00222026-04-17T09:00:00\u0022,\u0022subject\u0022:\u0022Week 8 Day 4 \u2014 Scenario drills \u002B check AI-102 objective mapping\u0022,\u0022body\u0022:\u0022Answer 5 end-to-end design scenarios in 5\u20137 steps each, then verify each AI-102 objective maps to something you studied/built so there are no surprise gaps. https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-102/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-102/\u0022},{\u0022schedule\u0022:\u00222026-04-18T09:00:00\u0022,\u0022subject\u0022:\u0022Week 8 Day 5 \u2014 Re-read learning path summaries \u002B clean cheat sheets\u0022,\u0022body\u0022:\u0022Revisit the summaries/knowledge checks in both learning paths, then trim your cheat sheets to high-yield cues only so final review stays sharp. https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/training/paths/develop-generative-ai-apps-in-azure/\u0022},{\u0022schedule\u0022:\u00222026-04-19T09:00:00\u0022,\u0022subject\u0022:\u0022Week 8 Day 6 \u2014 Light recap \u002B schedule exam window\u0022,\u0022body\u0022:\u0022Keep it light: quick flashcards \u002B a 10-minute architecture explanation out loud, then schedule your AI-102 exam (or set a firm window) to lock in commitment. https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-102/\u0022,\u0022link\u0022:\u0022https://learn.microsoft.com/en-us/credentials/certifications/exams/ai-102/\u0022}],\u0022motivationMessages\u0022:[{\u0022schedule\u0022:\u00222026-02-24T18:00:00\u0022,\u0022body\u0022:\u0022Keep today\u2019s goal small and concrete: one Microsoft Learn module \u002B one artifact (notes/diagram). Those artifacts become your exam-time memory hooks.\u0022},{\u0022schedule\u0022:\u00222026-03-10T18:00:00\u0022,\u0022body\u0022:\u0022RAG week is where AI-102 starts to feel \u201Creal\u201D\u2014prioritize citations and grounding behavior over perfection, then iterate with your test set.\u0022},{\u0022schedule\u0022:\u00222026-03-24T18:00:00\u0022,\u0022body\u0022:\u0022Safety isn\u2019t extra work\u2014it\u2019s part of the architecture. If you can explain where checks happen and why, you\u2019ll score well on scenario questions.\u0022},{\u0022schedule\u0022:\u00222026-04-07T18:00:00\u0022,\u0022body\u0022:\u0022As you study Search \u002B Extraction, keep asking: \u2018What gets indexed, what gets returned, and what must be cited?\u2019 That clarity unlocks most design questions.\u0022},{\u0022schedule\u0022:\u00222026-04-14T18:00:00\u0022,\u0022body\u0022:\u0022Final stretch: focus on closing your top gaps, not re-reading everything. Measurable wins come from re-answering missed questions and tightening your decision trees.\u0022}],\u0022briefMessageToUser\u0022:\u0022Your reminders are scheduled as daily 60-minute nudges aligned to each week\u2019s objective and checkpoint artifacts. Follow each link, finish the module/task, and produce the small deliverable\u2014by Week 8 you\u2019ll have both exam recall and a defensible end-to-end AI-102 architecture story.\u0022}"}],"messageId":"chatcmpl-DBarKABe87DcZn0yW1tzRUGOpN33t"}]}}}